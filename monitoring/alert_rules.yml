groups:
- name: llm_security_alerts
  rules:
  - alert: HighToxicityDetected
    expr: toxicity_score > 0.9
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "High toxicity content detected"
      description: "Toxicity score of {{ $value }} detected in LLM pipeline"

  - alert: PIIDetected
    expr: pii_entities_found > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "PII detected in content"
      description: "{{ $value }} PII entities found in processed content"

  - alert: GuardrailsServiceDown
    expr: up{job="guardrails-service"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Guardrails service is down"
      description: "The guardrails service has been down for more than 1 minute"

  - alert: ModelServiceDown
    expr: up{job="model-service"} == 0
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "Model service is down"
      description: "The model service has been down for more than 2 minutes"

  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} errors per second"

  - alert: HighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High latency detected"
      description: "95th percentile latency is {{ $value }} seconds"
